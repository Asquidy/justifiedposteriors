# Priors & Posteriors Extracted from Justified Posteriors Transcripts

This document contains belief updates extracted from podcast transcripts using Opus.

## Batch 1: HTML Transcripts (10 episodes)

### Techno-Prophets Try Macroeconomics
**Paper:** GATE Model (Growth and AI Transition Endogenous) by Epoch AI

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 23% GDP growth in 2027 is ~1 in 1000 chance | 1 in 1000 chance of 20%+ GDP growth in 2027 |
| **Posterior** | Updated to ~1 in 999 (essentially unchanged). Model useful as bridging tool but not for prediction. | Stayed at 1 in 1000, possibly moved slightly down (anti-persuaded) |
| **Key insight** | Model bridges technologist-economist conversation but lacks key elements (fiscal policy, heterogeneous populations, realistic savings) |

### Evaluating GDPVal: OpenAI's Eval
**Paper:** GDP Val: Evaluating AI Model Performance on Real-World Tasks by OpenAI

| | Andrey | Seth |
|---|--------|------|
| **Prior** | AI wins vs human experts ~10% of the time | AI wins ~10% of the time; 90-95% of workers still "by hand" in 2 years |
| **Posterior** | Updated from 10% to ~30%. Skeptical of full 47.6% win rate. | Updated from 10% to 25-30%. Still expects 95% working "by hand" |
| **Key insight** | Claude Opus achieved 47.6% win rate near human parity. "Meeting problem" - AI can create artifacts but not social coordination. |

### Are We There Yet? Evaluating METR
**Paper:** Measuring AI Ability to Complete Long Tasks by METR

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 50/50 AI can do human-month task in 5 years, almost certain in 10 years | 50/50 in 5 years, >90% in 10 years |
| **Posterior** | More confident in 5 years (Opus 4.5 moved priors more than paper) | 5-year same, 10-year dropped from 90%+ to 70-80% |
| **Key insight** | 7-month doubling time influential but limited to software engineering. AIs still struggle with messy, coordinated tasks. |

### One LLM to Rule Them All
**Paper:** Demand for LLMs by Andrey Fradkin

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 60/40 towards more market concentration in 2 years | 85% probability of more concentration |
| **Posterior** | Unchanged. AI market will be more competitive than search or phone OS. | Unchanged. Multi-homing suggests horizontal differentiation. |
| **Key insight** | New models reach equilibrium penetration within weeks. Apps multi-home across models. |

### When Humans and Machines Don't Say What They Think
**Paper:** Political Correctness, Social Image, and Information Transmission + Anthropic's Chain-of-Thought paper

| | Andrey | Seth |
|---|--------|------|
| **Prior** | Expected large gap for trans athletes (~45%), small for trigger warnings | Expected campus issues to show biggest gaps. 50% that CoT helps understand AI |
| **Posterior** | Effects surprisingly uniform (0.1-0.2 SD). Racial microaggressions showed biggest gap. | Racial microaggressions biggest gap. Moved from 50% to 60-70% that AI can't fully represent internal understanding. |
| **Key insight** | Preference falsification is small and uniform. Republicans show more falsification at UCSD. AI CoT doesn't reliably reflect decision processes. |

### Claude Just Refereed the Anthropic Paper
**Paper:** Anthropic Economic Index

| | Andrey | Seth |
|---|--------|------|
| **Prior** | Expected writing/programming to dominate; office/admin highly represented | Expected 80%+ to be coding and homework |
| **Posterior** | Confirmed writing/programming. Surprised by low office/admin usage. | Not moved - coding/writing ~50%. Surprised by low managerial task usage. |
| **Key insight** | 37% computer/math tasks vs 3.4% of workforce. Claude critiqued the paper for "unsubstantiated leaps" in mapping conversations to tasks. |

### Will Super-Intelligence's Opportunity Cost Save Us?
**Paper:** We Won't Be Missed by Pascual Restrepo

| | Andrey | Seth |
|---|--------|------|
| **Prior** | Skeptical asymptotic results tell us about 100-year horizon | >90% large labor share decline; <10% literally ~0% in 100 years; 70% real wages higher post-AGI |
| **Posterior** | Unchanged. Finite-time dynamics dominate asymptotic results. | Unchanged. Moved from 70% to 71% on wages. |
| **Key insight** | "Bottleneck" vs "accessory" work distinction determines human wages post-AGI. |

### Did Meta's Algorithms Swing the 2020 Election?
**Paper:** Social Media Feed Algorithms (Science)

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 80% confident algorithmic effects would be very small | 67% Facebook algorithms favor lefty candidates AND chaos/polarization |
| **Posterior** | Confirmed - effects essentially zero. Reduced belief ML ranking matters vs content moderation. | **67% to ~5% on polarization; 67% to ~30% on candidate effects. Biggest belief swing in podcast history.** |
| **Key insight** | Chronological feed users saw MORE political content and MORE untrustworthy news. Algorithm optimizes for engaging but anodyne content. |

### Scaling Laws Meet Persuasion
**Paper:** Scaling Language Model Size Yields Diminishing Returns for Persuasion (PNAS)

| | Andrey | Seth |
|---|--------|------|
| **Prior** | <1% super-persuasive AI is #1 safety risk. High confidence in diminishing returns. | 60% super-persuasive AI is top X-risk. 99% confidence in diminishing returns. |
| **Posterior** | Unchanged on risk. Confirmed diminishing returns at ~70B parameters. | 60% to 55% on risk. 99% to 99.9% on diminishing returns. |
| **Key insight** | Persuasion gains plateau around LLaMA 2 70B / Qwen 72B. GPT-4 and Claude Opus don't show additional persuasive power. |

### The Simple Macroeconomics of AI
**Paper:** Daron Acemoglu's paper

| | Andrey | Seth |
|---|--------|------|
| **Prior** | Small effects from current AI; potentially huge from science acceleration | 2-4pp additional growth/year over 20-50 years |
| **Posterior** | Median sucked down slightly. Paper fails to imagine new tasks and non-GDP benefits. | Median down slightly; 75th percentile unchanged. Realistic 66th percentile is ~3pp over decade. |
| **Key insight** | Acemoglu estimates <1pp TFP growth over decade. Key criticism: assumes technology never improves, only focuses on barely-better-than-human automation. |

---

## Batch 2: TXT Transcripts (10 episodes)

### Beyond Task Replacement
**Paper:** Tim Bresnahan's GPT paper

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 20% task replacement, 80% everything else (innovations, robotics, etc.) | 30-50% from naive task replacement |
| **Posterior** | Not shifted significantly. Already agreed with anti-task-replacement side. | Moved to <50% from task replacement. Task definition matters. |
| **Key insight** | Most AI economic benefit comes through capital deepening, reorganization, and new products rather than literal task replacement. |

### Is Social Media a Trap?
**Paper:** Bursztyn et al. on collective traps

| | Andrey | Seth |
|---|--------|------|
| **Prior** | Expected some would prefer world without social media | 5-10% made worse off by social media |
| **Posterior** | Surprised by magnitude - larger number than expected. | Updated to 20th percentile being made worse off. |
| **Key insight** | Social media may function as collective trap - individuals prefer using it given others use it, but collectively would prefer without. |

### AI and Its Labor Market Effects
**Paper:** Ide and Talamas

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 65% that 2% of workers manage AI agents in 5 years; 55% AI exacerbates polarization | 60% on 2% threshold; 25% AI exacerbates polarization |
| **Posterior** | No change. Paper's assumptions too limiting. | Moved 25% to 30% on polarization. |
| **Key insight** | Paper conflates managers and experts. Whether AI increases inequality depends on marginal problem value and skill differentiation. |

### Can Political Science Contribute?
**Paper:** Henry Farrell's "AI is Governance"

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 10% cultural technology framing useful | 60% AI needs new political science; 40% cultural technology framing |
| **Posterior** | Updated 10% to 15% on cultural technology framing | **60% to 90% on new political science; 40% to 80-90% on cultural technology** |
| **Key insight** | Political scientists have said remarkably little about AI. Essay ends right when interesting questions begin. |

### Emergency Pod: Is AI Already Causing Unemployment?
**Paper:** Canaries in the Coal Mine by Brynjolfsson et al.

| | Andrey | Seth |
|---|--------|------|
| **Prior** | +/-10% employment difference plausible; skeptical of large effects | 70% finding directional effect youth doing poorly in AI-exposed jobs |
| **Posterior** | AI story plausible but timing doesn't line up. Many confounders. | 95% convinced descriptive finding is real; 75% early-stage workers challenged by AI |
| **Key insight** | Entry-level employment in AI-exposed occupations declined since 2022, but timing/confounders make causal attribution uncertain. |

### Should AI Read Without Permission?
**Paper:** Books3 training data impact

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 50% improvement in cloze score from books. Worried about low memorization. | Expected halving of error rate from training on books |
| **Posterior** | Wrong - actual improvement ~20% or less. Surprised by little memorization. | Also wrong - baseline cloze ~10%. Moved toward keeping current copyright regime. |
| **Key insight** | AI models memorize surprisingly little (~10% cloze success). Book3 corpus largely redundant for popular books. |

### How Much Should We Invest in AI Safety?
**Paper:** Chad Jones papers

| | Andrey | Seth |
|---|--------|------|
| **Prior** | Willing to tolerate <1% annual X-risk. Single digit billions for safety. | 10% we should devote significant GDP fraction to safety |
| **Posterior** | Now willing to tolerate ~1% given healthcare/longevity benefits. Still skeptical of 15-30% GDP. | Not moved. Need to show machine that turns money into safety first. |
| **Key insight** | Optimal safety spending highly sensitive to risk aversion, mortality rates, time horizons. Log utility suggests tolerating ~40 years at 1% annual risk. |

### If the Robots Are Coming, Why Aren't Interest Rates Rising?
**Paper:** Chow, Halperin, Mazlish

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 10% low rates indicate markets don't believe AGI imminent | 90% confident low rates indicate no imminent revolutionary AGI |
| **Posterior** | Still skeptical but agree rates would move if AGI imminent | Increased to 95%. 80-90% elevated rates would appear 5+ years before AGI. |
| **Key insight** | Low real interest rates suggest markets don't anticipate transformative AI soon. Both good and catastrophic AI outcomes should cause higher rates. |

### Can AI Make Better Decisions Than Doctors?
**Paper:** Mullainathan and Obermeyer

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 90% doctors make substantial mistakes; 50% can identify with data | 90% doctors make documentable incorrect decisions |
| **Posterior** | Updated to 95% on identifiable mistakes. Cost per life-year could drop $89K to $59K. | Moved 50% to 85% mistakes can be identified. Natural experiment convincing. |
| **Key insight** | Doctors over-index on salient symptoms (chest pain) and under-use available data. Simple ML could substantially improve heart attack testing. |

### Robots for the Retired
**Paper:** Acemoglu and Restrepo on Demographics and Automation

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 40% demographics explains 20%+ of robot adoption variation; 70% aging increases automation | 75% aging has causal effect; 60% baby bust accelerates automation |
| **Posterior** | Updated to 50% on 20% explanatory power; 75% on aging increasing automation | Updated to 85% backward; 65% forward. Concerned about omitted "modernity" variable. |
| **Key insight** | Older societies adopt more robots. Effect works through relative scarcity of middle-aged workers. But youth may be essential for breakthrough innovation. |

---

## Batch 3: Mixed Files (11 files)

### A Resource Curse for AI (The Intelligence Curse)
**Paper:** Luke Drago and Rudolph Lane

| | Andrey | Seth |
|---|--------|------|
| **Prior** | 55% AI lets elites be less responsive by 2050; 20% new social contract | 60% elites less responsive; 20% new social contract |
| **Posterior** | 57% on elite responsiveness (slight increase); 20% social contract (no change) | 62% on elite responsiveness; 20% social contract (no change) |
| **Key insight** | Paper is better as scenario analysis than prediction. Every step on the path is fairly contingent. |

### Situational Awareness
**Paper:** Leopold Aschenbrenner's essay

| | Andrey | Seth |
|---|--------|------|
| **Prior** | Skeptical of rapid AGI timeline (~5% implicit) | Skeptical of scaling law predictions |
| **Posterior** | Maintains skepticism; AI democratizing technology for human capital | Moved toward accepting national security framing |
| **Key insight** | Essay is provocative; scaling law argument more novel than historical AGI predictions. Competition dynamics and national security implications significant. |

### Interview Episodes (no explicit priors/posteriors):
- **Ben Golub: AI Referees & Social Learning** - Discussion of Refine.ink, DeGroot model
- **Does AI Cheapen Talk? (Bo Cowgill Part 1)** - GenAI leads to 4-9% information loss in screening
- **Epistemic Apocalypse and Prediction Markets (Part 2)** - Jakobson's functions of language framework
- **What Can We Learn from AI Exposure Scores? (Daniel Rock)** - Exposure is not automation; we're in J-curve investment stage

### Blog Posts (no transcripts):
- **High Prices, Higher Welfare: Auto Industry** - Episode description only
- **Sci-Fi Economics** - Blog post about methodology

---

## Key Patterns

### Biggest Belief Updates
1. **Seth on Meta's algorithm effects**: 67% to 5% on polarization (one of biggest swings ever)
2. **Seth on political science need**: 60% to 90% that we need new approaches for AI governance
3. **Both on AI vs human win rate**: 10% to 25-30% after GDPVal paper
4. **Both on ML identifying doctor errors**: 50% to 85%

### Most Stable Beliefs
- Diminishing returns to model scale (99%+ confidence before and after)
- Skepticism about super-persuasive AI as top X-risk (Andrey <1% throughout)
- Labor share decline post-AGI (Seth >90% throughout)
- Social contract by 2050 (both at 20% before and after)

### Recurring Themes
1. **Diffusion friction** - Technology exists before economic impact materializes
2. **Asymptotic vs finite-time** - Academic models often don't translate to near-term predictions
3. **Definition problems** - What counts as "persuasion," "economic task," "automation"
4. **Selection/representativeness** - Claude users, UCSD students, software tasks may not generalize
5. **Missing mechanisms** - Capital accumulation, international effects, non-GDP welfare often omitted
