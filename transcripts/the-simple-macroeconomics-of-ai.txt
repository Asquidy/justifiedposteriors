Seth Benzel: It's a complete non sequitur in the paper. It reveals a kind of—utterly—"Luddite" is too strong, but a very pessimistic worldview where he goes and he says through this paper, "Well, I'm going to look at the effects of only automation. The technology is never going to get better." And of course, in my model, if we invent new tasks, that's very beneficial for the economy. But the only tasks that I'm going to contemplate innovating in are "bad" tasks.
[Intro Music]
Announcer: This is Justified Posteriors, brought to you by the Digital Business Institute at Boston University's Questrom School of Business.
Seth Benzel: Welcome, everyone, to the Justified Posteriors podcast, where we read economics papers and get persuaded by them so you don't have to. I'm Seth Benzel, with 4.6% of my tasks automated, coming to you from Orange, California.
Andrey Fradkin: And I'm Andrey Fradkin, coming to you from a perfectly competitive economy in Cambridge, Massachusetts. Very excited to discuss this topic. So what are we talking about today? It's the big question, the one that everyone is talking about, which is: what is AI going to do to the economy? It seems like we can't get away from this question. And as economists, I think we're supposed to have a slightly more informed prior on this question than maybe others. So, Seth, what is your prior? What was your prior before you read this paper?
Seth Benzel: All right. So just to give some context, we're going to be reading The Simple Macroeconomics of AI from Daron Acemoglu, fresh off the presses. Before reading this paper, I had done some analyses myself of the economic growth impact of AI technologies. I think an increase of three to four more percentage points of growth per year would be a very dramatic but possible effect, kind of at the upper end of my range. I've also seen estimates where automation is a little bit more of a "nothing burger" and estimates where automation is going to completely change everything. And so I would say my point estimate of the effect of AI on economic growth is maybe two to four percentage points of additional growth per year. But I would say that's with wide confidence intervals.
Andrey Fradkin: And over how many years are you taking this average?
Seth Benzel: That's important. So when I'm thinking about this, I'm thinking about an average rate maybe over the next 20, 30, 40, 50 years. And I do think some of those gains will be backloaded, but certainly, I think two percentage points per year over the next 10 years—if everything goes above average, but not fantastic, maybe a 75th percentile outcome—is not unreasonable.
Andrey Fradkin: All right. Well, that's a very interesting estimate. I think as a non-macroeconomist, I have maybe a less calibrated economic growth picture. I'm not usually thinking about entire economies with all sorts of types of labor. I tend to be in the camp of small effects if we're thinking of AI as just, you know, us using ChatGPT a little in our jobs. I don't see how a little bit of ChatGPT in our jobs is going to lead to several percentage points per year. But I think the potentially huge effects are acceleration of science, the breaking down of existing institutional structures, and effects on political economy. I would also say that I am certainly abstracting away from an artificial superintelligence scenario where we just have superior-to-human-in-all-dimensions agents living in the cloud operating at a faster-than-human scale. So if we do hit that, I'm taking that out.
Seth Benzel: That's in my distribution, but I don't want to put it in my average prediction, right? Maybe we should focus on median predictions, and then the range of possible predictions is a good way of thinking about this, right? Because ultimately, we're going to get a point estimate from Acemoglu, and maybe we can talk about how small that estimate is in a second. But he doesn't give us that many tools to think about ranges around that. Maybe this is better thought of as a median case outcome than an average case outcome if you think there's a 1% chance of some sort of crazy outcome.
Andrey Fradkin: Yeah, that's certainly true. So I guess, why are we even reading this paper? I think there are two reasons. I think there's been a call from informed observers such as Tyler Cowen that there needs to be serious quantification exercises around the effects of AI. And to do that, you need a macroeconomic model where we model all the industries in the economy at once. And so someone needs to make such a model that is applicable to AI. And this is an example of that. The second is, of course, that it's Daron Acemoglu.
Seth Benzel: High praise for Daron.
Andrey Fradkin: I was going to say that Daron is one of the most prolific economists ever in the history of economists, who has transformed many fields and is considered one of the sharpest thinkers out there. Anything he writes, we should pay attention to. I view this paper as kind of like the "standard macro" answer to some of these very interesting questions that a lot of people in technology have been asking. And so what better place to start? What's beautiful about economics is that all the assumptions are laid out on the table in a way that I think otherwise we wouldn't necessarily get them. It allows us to critically evaluate the different pieces of these models and the different assumptions that are made.
Seth Benzel: Maybe it's time for us to introduce the headline result, which is his big-picture finding: AI is unlikely to make a large TFP (Total Factor Productivity) or welfare contribution in the next 10 years, with his point estimate coming in at less than one percentage point of additional growth over the entire decade—less than 0.1 percentage points per year. What was your initial reaction when you saw that number?
Andrey Fradkin: Honestly, my reaction... Well, one is it seems small, right? I mean, I think anyone looking at this number would be like, "this is pretty damn small." My reaction to macroeconomic models is to look for where the skeletons are hidden. And that intrigued me. I like to think of myself as a necromancer of a sort.
Seth Benzel: You're going to make those skeletons in the closet sing, dude?
Andrey Fradkin: So I think every argument has hidden skeletons, but the beauty of macroeconomic models is you can see those skeletons very clearly, and then you can decide whether those should be alive or not. With that, I think we can get to the different steps that are involved in building this type of model. Great.
Seth Benzel: Like, don't you have to take a stance on what AI is in order to make a model of AI?
Andrey Fradkin: Truly one must. He defines AI here really broadly, analogously to the main paper that he draws on. If we want to talk about his empirical estimates, he's talking about the famous "GPTs are GPTs" paper from Eloundou et al., co-authored by a friend of the podcast, Daniel Rock. In that paper, they're looking at what range of tasks currently performed in the U.S. economy can plausibly be sped up by two times or more using current-generation LLMs plus current-generation APIs.
Seth Benzel: Well, with the one caveat that he also incorporates computer vision technology and estimates from Svanberg. So I think it would be LLMs and computer vision, if I understand correctly.
Andrey Fradkin: I believe computer vision is handled in the Eloundou et al. paper through the ability to "plug into" other APIs.
Seth Benzel: Okay. So yeah, it's a very interesting definition. I think one way to think about it is to imagine we had perfect diffusion of the current technologies that are already available and in wide use...
Andrey Fradkin: ...and they never get any better. The preview of GPT-3.
Seth Benzel: Yes, and they never get any better. While this does sound a little bizarre to people who are seeing it get better month by month, you do need to make this model, and you need to put some data into it. We don't really have data on the models that are going to be better and coming out in a year or two. So I think he's standing on semi-solid ground by using what we already have data about.
Andrey Fradkin: Right. I think the thought experiment here is: what happens after perfect diffusion of current-generation AI?
Seth Benzel: I'd be shocked if current technologies diffuse 100% in the next 10 years. We know from the history of technology and technological spread that it takes a very long time to diffuse, especially when you need to change how you organize a firm or an industry in response to new production technology.
Andrey Fradkin: Right.
Seth Benzel: So I think, if you really pushed the author, I'd imagine he'd tell you that there's an overestimate of the true effect because there's no way that we're going to get 100% diffusion of these AI technologies in the next 10 years.
Andrey Fradkin: So here's one way of thinking about this diffusion rate that isn't explicitly in the paper, but you can kind of back out: thinking about this as the rate at which labor's share of national income decreases. Historically, labor's share of national income has decreased by maybe about half a percentage point per year. This model, by saying 4.5% of tasks are automated, is predicting a faster rate of robots taking jobs than the 20- or 40-year historical average. It's about maybe four times the historical rate. So this is a fast rate of automation in this paper.
Seth Benzel: Yeah, I think we're on the same page. Once again, it's best to think of this as a kind of thought experiment. I think we just have to acknowledge that he's not thinking about diffusion at all.
Andrey Fradkin: Right. I think maybe I'll take one minute here to say one other thing that I don't see in the paper, which is thinking about differences across countries. This is a one-country model. I think there are first-order implications of automation in a multi-country model where you might have greater capital investment through "capital stealing" from poorer countries as a result of automation—that's going to be something that benefits automating countries. That's not in the way that Daron thinks about capital accumulation here, which is in a very stylized way. You have to think about capital accumulation because if somebody says robots are going to take your jobs, then your next question's got to be, "Well, how many robots are going to take my jobs?"
Seth Benzel: Yes. I think that's a very noteworthy caveat, especially if we're trying to make quantitative predictions about GDP that we could bet on a betting market. Those things would be really, really important. But I'm not so bothered by the lack of this mechanism here, because there's already a lot going on in this model, and we can happily abstract away from capital stealing, which is not really what a lot of AI boosters or AI worriers are particularly worried about.
Andrey Fradkin: Right. We can return to this point in our conclusion, but I would not sleep on capital accumulation as an important mechanism for what AI does to the economy.
Seth Benzel: Yeah. So I think, obviously, we're not going to go through the math in a podcast. That seems impossible.
Andrey Fradkin: Obviously.
Seth Benzel: But I think the key features of macroeconomic models are all present here. The key modeling device that Daron has used in his previous papers, and is also using in this one, is a task-based model. In a task-based model, the key thing to know is there are a bunch of tasks. Some of those tasks are going to be done by capital; some are going to be done by labor. The model creates conditions under which those tasks go in which bin. As a result, the model allows you to think about various forces by which AI is going to improve productivity. Would you please give me an industry to use as an example?
Andrey Fradkin: The podcast mic manufacturing industry.
Seth Benzel: The podcast mic manufacturing industry. Well, I won't name any brand names because we're holding out for the sponsorship, but you might imagine making microphones requires two tasks. The first is making a microphone, and the second is making a cable that allows you to plug the microphone into your laptop. We invent a radical new technology that allows for robots alone to create the microphone part. That would be an example of us expanding the range of tasks that can be done by capital. You now have the choice of making the microphone with a robot. And now the question is, will you choose to make the microphone with a robot? That's going to depend on the relative productivity of a worker versus capital, as well as the relative costs of labor and capital. So when interest rates are high, you're going to want to do it with labor. And when workers are really expensive, you're going to want to do it with capital. That's kind of automation. There's also this issue of complementarity. To what extent do I need both the microphone and the cable? That's an example where there's close complementarity; one without the other doesn't help you. But you might also imagine situations where you can just do more of the automated thing and ignore the unautomated thing if they're not particularly complementary. Finally, you might imagine the labor itself getting more productive—maybe we educate the worker and they become better at making microphones faster. Or you might imagine capital technology changes. It used to be that you could use a computer and it would cost so much electricity to make a microphone of a certain quality. But technological changes might allow you to use that same robot to make the microphone better at a lower cost. That would be "capital deepening" of automation. The thing that you already automated is getting better.
Andrey Fradkin: So it's like the machine going to college.
Seth Benzel: Yeah. One example is a warehouse robot moving around pallets and boxes. If you've uploaded new software to this robot, and now it's able to move faster with weight on it, you need fewer of these in order to manage the same amount of warehouse space. That's capital deepening.
Andrey Fradkin: Truly. And now there's this final thing that could happen, which is you could create new tasks. We don't really get a lot of discussion of that in this paper, but his mechanism not only allows for it, it kind of requires it in certain long-range projections. I'm thinking of his "race between man and the machine" model. What is creating a new task, Andrey?
Andrey Fradkin: Well, podcasts didn't exist at some point. The job of a professional podcaster—how did people take showers? How did people walk to work without a podcast in their ear? Podcaster is an occupation, but let's be more precise. Some tasks, like vocalizing, presumably existed for radio hosts, but others, like marketing via social media, require different skills. Maybe a "social media manager" is a classic new task.
Seth Benzel: One thing I will say is if familiarity with social media counts as a new task, new tasks are sweeping the economy and he's ignoring it.
Andrey Fradkin: There is this very deep question about what tasks really are. Even in the paper, he talks about subtasks. In my opinion, an occupation is supposed to be a bundle of tasks. Is me vocalizing the words that I'm speaking right now a task or a subtask? You could argue both.
Seth Benzel: It's clear the taxonomy starts to break down here, and maybe we're not supposed to take the model that seriously.
Andrey Fradkin: They're kind of gesturing at something while avoiding the details.
Seth Benzel: Right. And one last thing: given that there's a range of tasks, some of which can be automated and some of which can't, there's the possibility that you might automate certain tasks that are just barely worthwhile—very marginal cost savings. In that situation, the "marginal task" divides the work done by machines from that done by humans.
Andrey Fradkin: So, okay, now that we've given some background about what's going into this soup—Daron's cooking up this soup, and in the soup is going to be the task-based model. He's putting GPTs, LLMs, and machine vision in. He mixes them together. What does he start to get? He starts to put some numbers on these things.
Seth Benzel: Generally, macroeconomic models can get very complicated, right? So you need to make some stark assumptions to make them simple so that you can do napkin math like he does in this paper. One of the key assumptions is that every industry in this economy is perfectly competitive.
Andrey Fradkin: Fuck yeah.
Seth Benzel: And, you know, this is usually not an assumption that someone from Cambridge, Massachusetts would be willing to make. This is more of a University of Chicago assumption.
Andrey Fradkin: And yet he is making it. I mean, Andrey, I guess I would say that I view this as sort of harmless. If a model where markups are fixed—such as in the classic Romer model of competition—that's just a 20% drag on the economy forever. I think you can imagine incorporating profits into this model pretty harmlessly while saving all the other predictions.
Seth Benzel: I don't know if I'd be happy with the Romer model. One thing I'm thinking about is that AI seems to be creating a boom in startups, and the degree of competition—which markets are contestable now—seems to be changing. That can exist in a model with perfect competition, or constant markup competition.
Andrey Fradkin: I guess where I come back on that is: imagine a universe where a company defeats Google because it invents a search engine that's 1% better. The business story there is incredibly dramatic—this trillion-dollar company gets replaced with another. But the macroeconomic story is just that one industry got 1% more productive.
Seth Benzel: Well, Andrey, I like to think about Baumol's cost disease. I think about industries characterized by regulatory capture and high barriers to entry that are starting to get hit.
Andrey Fradkin: Put your money where your mouth is. Where should I get my VIX derivatives? Which industry is going to have the most disruption?
Seth Benzel: Well, I think a lot about health-related occupations—health insurance, doctors, and other licensed professions. Also contractors for buildings; you might think that's one of the last jobs automated because it requires physical manipulation.
Andrey Fradkin: You took the words out of my mouth, Seth. Are you psychic?
Seth Benzel: Let me tell you what a major cost is involved in contracting: assessment and the filing of permits. If you can suddenly do that a lot faster, I imagine it might be easier to create competition in this industry.
Andrey Fradkin: But is that order-of-magnitude important? You increase competition, you drive down the margin from 20% to 5%—you get that amount more, but you're also using more societal resources. It's hard to argue that this is going to be first-order.
Seth Benzel: I go back to the fact that healthcare is a very large proportion of the economy, and I can imagine it becoming much more efficient. The other thing I'd say is something not directly captured in GDP: time savings.
Andrey Fradkin: Oh, that's true—the increase in leisure. But let's hold the unmeasured GDP benefits for later. I want to talk about these numeric estimates of AI exposure and cost savings. Daron has one main equation: the TFP benefit over the next 10 years from AI will be equal to the GDP share impacted by AI (literally automated) times the average cost savings of the impacted tasks. He has two numbers to estimate. The first—the GDP share impacted by AI over 10 years—he gets by multiplying two numbers. He starts with the Eloundou et al. paper and says 20% of U.S. labor tasks are going to be exposed to AI. (Important caveat: this is not how Daniel Rock says you should use his paper). Then he multiplies that by 23%—from another study saying that's the share of "exposed" tasks actually productive to automate. Multiply those, and you get 4.6% of tasks ready to be automated. What do you think of that calculation, Andrey?
Andrey Fradkin: It's interesting. I think both of us have read enough science fiction to know that seems like a very low amount. But let's be charitable: let's assume we are freezing technology at the last version released when that paper was written.
Seth Benzel: Which is even maybe earlier.
Andrey Fradkin: Yes. Let's say we've had a year of living with that technology. What share of our own tasks has been automated? Some—writing outlines, form letters, etc.
Seth Benzel: "Give me a list of Mondays and Wednesdays for my syllabus."
Andrey Fradkin: Yeah, it's useful, but in terms of the share of my tasks actually automated...
Seth Benzel: Above or below 4.6%?
Andrey Fradkin: In terms of time usage, there are cases where it has saved me enormous amounts of time. I haven't dug deeply enough into the weeds: should I be thinking of this per time unit of task or in units of tasks?
Seth Benzel: In principle, you should be multiplying them by the marginal productivity of the task. And now, Andrey, I do know that you are optimizing at all times and your marginal productivity of every action is exactly identical, so maybe we can elude that complication.
Andrey Fradkin: Fair enough. But from a personal level, I do a lot of things; very few have been automated. The things that have—like a code refactor—saved me maybe five days over a year. So maybe it goes back to this 5% number.
Seth Benzel: Right. So that's the first number: 4.6% of GDP automated. The second number is the average cost savings in each automated task. If you didn't like the 4.6% number, you're really not going to like this one: he estimates we're going to save only 15.4% off our previous costs.
Andrey Fradkin: What? That seems low. I thought "automated" meant we save all the costs.
Seth Benzel: Well, there are always the electricity costs of the machine.
Andrey Fradkin: Yes, of course.
Seth Benzel: But he estimates that in tasks exposed to AI, you reduce labor costs by 27%. Then he multiplies that 27% by approximately 57% (the labor share of the economy) to get this 15.4% overall total saving. Aggregate that with the 4.6% of tasks automated over 10 years, and it's not a crazy number—even my optimistic scenario only puts it at about twice that. But the 15.4% cost reduction just seems hopelessly low. He cites papers, but I think they make two big mistakes. First, they subtract any "rising tide lifts all boats" effect—background automation that helps every firm. You might imagine AI boosts GDP in ways that are hard to estimate using these tools. Second is the "staticness" of that number. That's a short-term estimate from having automated for a few months. Over time, we expect computers to get better and better at these tasks. This is why we sometimes refer to this paper as estimating the effect of technologies that are barely better than humans and never get any better.
Andrey Fradkin: Yeah. You're saying the technology will keep getting better. Another way to think about it: if you operating a call center and gave half the people AI tools, even holding the technology constant, people are going to learn how to use it way better over time. The effects are going to be way bigger than 15%. Also, what about imperfect competition in the labor market? Companies don't like firing people. If half of a person's tasks are automated, they might still not be fired. In that case, what are your cost savings? Zero. These papers might not be the right ones to think about this.
Seth Benzel: And you don't even need imperfect competition; you could have "nominal rigidity" where people refuse to take pay cuts, and adjustments happen slowly as firms fail to give inflation raises because half your tasks were automated.
Andrey Fradkin: Exactly. If you have a lot of labor regulations, it might not make sense to invest in automating technologies because you can't realize the labor savings.
Seth Benzel: Which might then auger for a startup company that uses less labor to provide drastic productivity improvements over incumbents.
Andrey Fradkin: Presumably, once that company comes along, we would get these micro-estimates of big positive effects.
Seth Benzel: Yes, exactly.
Andrey Fradkin: But maybe this is a good time to talk about why Daron is actually pessimistic. He thinks we're estimating the impact from having automated "easy" things, and all the other things on the list are necessarily harder to automate. Do you buy that argument?
Seth Benzel: I thought those numbers were an average over the easy and hard tasks to some extent.
Andrey Fradkin: It's the average over the easy and the hard tasks that have already been automated.
Seth Benzel: I agree it asks us to engage in pure speculation. Silicon Valley is optimistic, and at least some investors are too. This distinction between "easy" versus "hard" to automate tasks seems like a static, second-order question compared to the fact that the stuff we already automate will get better over time.
Andrey Fradkin: I agree. We've already automated a huge portion of things we do, so why not get better at it?
Seth Benzel: Let's move quickly past the inequality implications; he doesn't have anything particularly novel to say there.
Andrey Fradkin: Well, I think we missed one thing: the distinction between effects on GDP and TFP. His number so far is just the gains to productivity—technological improvements that make things better.
Seth Benzel: "More from less."
Andrey Fradkin: Yeah. But there's another portion of GDP: someone's building those data centers and robots. That capital used for future production should also go to GDP. He says it's similarly small. Do you think that's reasonable?
Seth Benzel: As I said, I stand capital accumulation as essential for thinking about long-term impacts. In a fully automated economy, output growth is the growth rate in technology times the growth rate in the capital stock. If your country suddenly shows up with exciting new high-tech investment opportunities—as AI is doing for America—that's going to draw in capital from abroad. Depending on how small America is relative to the rest of the world, that effect could be massive. The benefit might not come directly from the technology, but from making the country a more attractive investment.
Andrey Fradkin: That's quite interesting. We see a lot of interest in investing in NVIDIA—presumably not just from Americans. Okay, I think that's a clear limitation of this approach. But do we now want to talk about the negative effects of AI, or wrap it up?
Seth Benzel: Let's reframe this: what's not in GDP that might come from AI? The headline argument is AI isn't going to change welfare much over 10 years, and it might actually lower welfare because we might invent some "bad" things. He focuses on one particular negative impact. What is that one, Andrey?
Andrey Fradkin: We're going to make social media even more addictive through the generation of content. This is terrible because, even though we all use it, if we could all agree not to use it, the world would be a better place.
Seth Benzel: Or so one survey says.
Andrey Fradkin: Yes. The argument is not a very new one. It's the "keeping up with the Joneses" problem. If everyone decides a nice car signals you're a good person, everyone competes to buy a fancier car. But if you could wave a magic wand and have everyone drive the base model, the world would be better.
Seth Benzel: Ramblings of the utterly deranged. Incredible. "The real GDP growth is when we all become hermits and content with what we have." Thank you, Daron. That's what we want from economists.
Andrey Fradkin: It's an argument very reminiscent of communist arguments against capital's consumption culture.
Seth Benzel: Until the Khrushchevian reforms where he wanted to compete with capitalism on its own merits.
Andrey Fradkin: I raise the issue of cars to say there's nothing particularly special about social media.
Seth Benzel: It's a complete non sequitur in the paper. It reveals a pessimistic worldview where technology never gets better. In his model, new tasks are beneficial, but the only tasks he contemplates innovating in are "bad" tasks. He focuses on a single paper showing a negative impact, ignoring the vast obvious importance of all the free digital goods we consume. It seemed like motivated reasoning.
Andrey Fradkin: To me, it seems crazy to think the most important thing for welfare is that it's going to make me spend more time on social media.
Seth Benzel: It's absurd. It almost feels like he wanted to get a "technology is bad" answer. Why else focus on that one downside instead of the many upsides—from free tabletop RPG campaigns to AI companions that might make people feel happy?
Andrey Fradkin: This paper demonstrates a lot that's good and bad about economics. It's great because it lays out its assumptions, but economic models are also built to be enormously conservative. Everything is "at the margin," and marginal changes have marginal effects.
Seth Benzel: You need a "multiple equilibrium" model for anything radical.
Andrey Fradkin: So maybe it's not surprising we get a small number. But the overall mindset that permeates the profession is very conservative. Choosing to focus on "new bad tasks" is a failure of imagination.
Seth Benzel: On that note, let's move into conclusion mode. It's time for us to justify our posteriors, Andrey. You came in with a certain view of the effect of AI. Acemoglu tells us we should anticipate a less than one percentage point increase in aggregate TFP in 10 years. Has your prior moved?
Andrey Fradkin: I think a lot of thinking about AI is that there's some emergent thing—with a better GPT-like model, we're going to create something sweeping for society. If that happens in the next 10 years, it would be depressing if GDP increased less than 1%. But economies are slow to adjust—regulations need to change. If we don't have a very innovative new version of GPT, and given that this paper assumes perfect diffusion of the existing technology and still gets low numbers, I'm forced to conclude the GDP effects are maybe a little less than I would have thought.
Seth Benzel: So it would be fair to say we've sucked down your median outcome, but your top-percentile outcomes are not moving.
Andrey Fradkin: Yes.
Seth Benzel: I will say reading this paper gave me context for my quantitative predictions. In an optimistic scenario (but not transformative AI), I think twice this amount of tasks gets automated with 50% higher benefits. In that case, instead of adding one percentage point over a decade, we would add something more like 30 percentage points—especially taking into account capital accumulation. Am I being sucked down to his opinion? Maybe a little bit. It's hard to read something this carefully reasoned and not feel there's insight. But there are big omissions that make me think it's an underestimate. I remain convinced there's a non-trivial chance we unlock major speedups in technological innovation by the end of the decade.
Andrey Fradkin: I keep going back to diffusion. Let's say in year five we invent a cure for all cancers. That cure will not be passed by the FDA for how many years? Ten years?
Seth Benzel: Could be.
Andrey Fradkin: So we can't take lightly this idea that diffusion is going to screw over the macroeconomic effects.
Seth Benzel: Right. And the question is: ten years from now, what level of technology has diffused? The ten-year-old version or the five-year-old version?
Andrey Fradkin: Yes. And can you just "plug in" the newer model into a process designed for an older model?
Seth Benzel: Or does a better model cause an additional reorganization? My money is on this stuff getting easier to update over time. Once you put ChatGPT-4 in charge, going to GPT-5 is a smaller job than going from a human.
Andrey Fradkin: Yes. The only uncertainty is if we had to reorganize the economy to fully reap the rewards.
Seth Benzel: Maybe what we read next is something about adjustment tasks in putting in automation.
Andrey Fradkin: Yes, this discussion highlights how rich the surface is. To get a reasonable goal at what GDP will be like in 10 years, we have to understand a lot of different literatures.
Seth Benzel: I think that's exactly right. Let's sign off here and congratulate our listeners for making it through an episode of Justified Posteriors.
Andrey Fradkin: Thanks for listening to Justified Posteriors. Look for more episodes in the future and check us out on Substack and X.
Seth Benzel: We're telling you the rules / Our aim is plain to see...
[Outro Music]